name: Load/Save cache using cloud storage
author: Yuki Furuta
description: Load/Save cache using cloud storage

inputs:
  method:
    description: "'check', 'load', 'save' or 'clear'"
    required: true
  path:
    description: Path to directory to load/save cache relative to $GITHUB_WORKSPACE. Required for 'load' and 'save' method
    default: ''
  remote_path:
    description: Path to remote storage. (i.e. s3://target-bucket, /_local/_path)
    required: true
  key:
    description: Key to the cache (id of the save action). Required for load method
    default: '${{ github.action }}'
    required: true
  include:
    description: Include files that matches to the parameter.
    default: "**"
  exclude:
    description: Exclude files that matches to the parameter. Leave it blank if all files are included
    default: '.'
  compress_level:
    description: Compress level
    default: 11
  # parameters for AWS
  aws_access_key_id:
    description: AWS Access key ID
    default: ''
  aws_secret_access_key:
    description: AWS Secret access key
    default: ''
  aws_region:
    description: AWS region
    default: ''
  storage_class:
    description: Storage class to be used in storage
    default: "ONEZONE_IA"
    required: true

outputs:
  remote_path_exists:
    description: true is set if remote path exists
    value: ${{ steps.cache_s3.outputs.remote_path_exists == 'true' || steps.cache_local.outputs.remote_path_exists == 'true' }}
  prefix:
    description: Prefix for cache
    value: ${{ steps.cache_key.outputs.prefix }}
  key:
    description: Escaped key for cache
    value: ${{ steps.cache_key.outputs.key }}

runs:
  using: composite
  steps:
    - name: Set cache key
      shell: bash
      id: cache_key
      run: |
        CACHE_PREFIX="${{ github.repository }}"
        if [[ -n "${{ github.base_ref }}" ]]; then
          CACHE_PREFIX="${CACHE_PREFIX}/${{ github.base_ref }}"
        else
          CACHE_PREFIX="${CACHE_PREFIX}/${{ github.ref_name }}"
        fi
        CACHE_KEY="${CACHE_PREFIX}/$(echo "${{ inputs.key }}" | sed -e 's@[^a-zA-Z0-9_\-]@-@g')"
        echo "prefix=${CACHE_PREFIX}" >> $GITHUB_OUTPUT
        echo "key=${CACHE_KEY}" >> $GITHUB_OUTPUT
    - name: ${{ inputs.method }} cache (local)
      id: cache_local
      if: inputs.remote_path && ! startsWith(inputs.remote_path, 's3://')
      shell: bash
      run: |
        [[ "$(which zstd)" != "" ]] || apt-get install -qq -y zstd
        [[ "$(which tree)" != "" ]] || apt-get install -qq -y tree

        if [[ -e ${{ inputs.remote_path }}/${{ steps.cache_key.outputs.key }}.cache ]]; then
          echo remote_path_exists=true >> $GITHUB_OUTPUT
        fi
        if [ "${{ inputs.method }}" = "check" ]; then
          exit 0
        elif [ "${{ inputs.method }}" = "clear" ]; then
          echo "Clearing local cache is not supported for security reason"
          exit 1
        fi

        if [ -z "${{ inputs.path }}" ]; then
          echo "Input parameter 'path' is empty"
          exit 1
        fi
        mkdir -p ${{ inputs.path }} && cd ${{ inputs.path }}
        if [ "${{ inputs.method }}" = "save" ]; then
          NUM_TARGETS=$(find . -iwholename './${{ inputs.include }}' -not -iwholename './${{ inputs.exclude }}' | wc -l)
          if [ ${NUM_TARGETS} -gt 0 ]; then
            symlinks -cr . 1>/tmp/symlinks.log
            if [[ -n "${RUNNER_DEBUG}" ]]; then
              cat /tmp/symlinks.log
            fi
            mkdir -p $(dirname "${{ inputs.remote_path }}/${{ steps.cache_key.outputs.key }}.cache")
            find . -iwholename './${{ inputs.include }}' -not -iwholename './${{ inputs.exclude }}' -print0 | tar -c --no-recursion --null -T - | zstd -z -${{ inputs.compress_level }} -T0 - -o ${{ inputs.remote_path }}/${{ steps.cache_key.outputs.key }}.cache.new
            mv -f ${{ inputs.remote_path }}/${{ steps.cache_key.outputs.key }}.cache.new ${{ inputs.remote_path }}/${{ steps.cache_key.outputs.key }}.cache
            echo "${NUM_TARGETS} files/directories were saved to local ${{ steps.cache_key.outputs.key }}"
            ls -l ${{ inputs.remote_path }}/${{ steps.cache_key.outputs.key }}.cache
          else
            echo "No data found to save to local ${{ steps.cache_key.outputs.key }}"
          fi
        elif [ "${{ inputs.method }}" = "load" ]; then
          TARGET=$(ls -l ${{ inputs.remote_path }}/${{ steps.cache_key.outputs.key }}.cache 2>/dev/null || echo)
          if [ -n "${TARGET}" ]; then
            echo "Cache found"
            echo "${TARGET}"
            cat ${{ inputs.remote_path }}/${{ steps.cache_key.outputs.key }}.cache | zstd -d -T0 - | tar -x .
            echo "Cache were loaded from ${{ steps.cache_key.outputs.key }}"
            if [[ -n "${RUNNER_DEBUG}" ]]; then
              tree -a -I .git
            fi
          else
            echo "No local cache found to load from ${{ steps.cache_key.outputs.key }}"
          fi
        else
          echo "Invalid method you have specified ${{ inputs.method }}"
          exit 1
        fi
    - name: Setup AWS tools
      if: inputs.remote_path && startsWith(inputs.remote_path, 's3://')
      shell: bash
      run: |
        if [[ "%(which pip)" = "" ]]; then
          apt-get install -qq -y python3-pip python-is-python3
          update-alternatives --install /usr/bin/pip pip "$(realpath $(which pip3))" 3
        fi
        if [[ "$(which aws)" = "" ]]; then
          [[ "$(which curl)" != "" ]] || apt-get install -qq -y curl
          [[ "$(which unzip)" != "" ]] || apt-get install -qq -y unzip
          ( ( curl -o awscliv2.zip "https://awscli.amazonaws.com/awscli-exe-linux-$(uname -m).zip" && unzip awscliv2.zip -d /tmp/ && /tmp/aws/install && rm -f awscliv2.zip ) || pip install --no-cache-dir awscli )
        fi
    - name: Configure AWS Credentials
      uses: aws-actions/configure-aws-credentials@v1
      if: inputs.remote_path && startsWith(inputs.remote_path, 's3://') && (inputs.aws_access_key_id || inputs.aws_secret_access_key || inputs.aws_region)
      with:
        aws-access-key-id: ${{ inputs.aws_access_key_id }}
        aws-secret-access-key: ${{ inputs.aws_secret_access_key }}
        aws-region: ${{ inputs.aws_region }}
    - name: ${{ inputs.method }} cache (S3)
      id: cache_s3
      if: inputs.remote_path && startsWith(inputs.remote_path, 's3://')
      shell: bash
      run: |
        [[ "$(which zstd)" != "" ]] || apt-get install -qq -y zstd
        [[ "$(which tree)" != "" ]] || apt-get install -qq -y tree
        [[ "$(which symlinks)" != "" ]] || apt-get install -qq -y symlinks

        TARGET=$(aws s3 ls ${{ inputs.remote_path }}/${{ steps.cache_key.outputs.key }}.cache || echo)
        if [ -n "${TARGET}" ]; then
          echo remote_path_exists=true >> $GITHUB_OUTPUT
        fi
        if [ "${{ inputs.method }}" = "check" ]; then
          exit 0
        elif [ "${{ inputs.method }}" = "clear" ]; then
          if [ "${{ inputs.key }}" = "all" ]; then
            aws s3 rm --recursive ${{ inputs.remote_path }}/${{ steps.cache_key.outputs.prefix }}
          else
            aws s3 rm ${{ inputs.remote_path }}/${{ steps.cache_key.outputs.key }}.cache
          fi
          exit 0
        fi

        if [ -z "${{ inputs.path }}" ]; then
          echo "Input parameter 'path' is empty"
          exit 1
        fi
        mkdir -p ${{ inputs.path }} && cd ${{ inputs.path }}
        if [ "${{ inputs.method }}" = "save" ]; then
          NUM_TARGETS=$(find . -iwholename './${{ inputs.include }}' -not -iwholename './${{ inputs.exclude }}' | wc -l)
          if [ ${NUM_TARGETS} -gt 0 ]; then
            symlinks -cr . 1>/tmp/symlinks.log
            if [[ -n "${RUNNER_DEBUG}" ]]; then
              cat /tmp/symlinks.log
            fi
            find . -iwholename './${{ inputs.include }}' -not -iwholename './${{ inputs.exclude }}' -print0 | tar -c --no-recursion --null -T - | zstd -z -${{ inputs.compress_level }} -T0 - | aws s3 cp --storage-class ${{ inputs.storage_class }} - ${{ inputs.remote_path }}/${{ steps.cache_key.outputs.key }}.cache
            echo "${NUM_TARGETS} files/directories were saved to ${{ steps.cache_key.outputs.key }}"
            aws s3 ls ${{ inputs.remote_path }}/${{ steps.cache_key.outputs.key }}.cache
          else
            echo "No data found to save to ${{ steps.cache_key.outputs.key }}"
          fi
        elif [ "${{ inputs.method }}" = "load" ]; then
          if [ -n "${TARGET}" ]; then
            echo "Cache found"
            echo "${TARGET}"
            aws s3 cp ${{ inputs.remote_path }}/${{ steps.cache_key.outputs.key }}.cache - | zstd -d -T0 - | tar -x .
            echo "Cache were loaded from ${{ steps.cache_key.outputs.key }}"
            if [[ -n "${RUNNER_DEBUG}" ]]; then
              tree -a -I .git
            fi
          else
            echo "No cache found to load from ${{ steps.cache_key.outputs.key }}"
          fi
        else
          echo "Invalid method you have specified ${{ inputs.method }}"
          exit 1
        fi
    - name: Print results
      shell: bash
      run: |
        echo "steps=${{ toJson(steps) }}"

