name: Load/Save cache using cloud storage
author: Yuki Furuta
description: Load/Save cache using cloud storage

inputs:
  method:
    description: "'load', 'save' or 'clear'"
    required: true
  path:
    description: Path to directory to load/save cache relative to $GITHUB_WORKSPACE. Required for 'load' and 'save' method
    default: ''
  remote_path:
    description: Path to remote storage. (i.e. s3://target-bucket, /_local/_path)
    required: true
  key:
    description: Key to the cache (id of the save action). Required for load method
    default: '${{ github.action }}'
    required: true
  include:
    description: Include files that matches to the parameter.
    default: "**"
  exclude:
    description: Exclude files that matches to the parameter. Leave it blank if all files are included
    default: '.'
  compress_level:
    description: Compress level
    default: 11
  storage_class:
    description: Storage class to be used in storage
    default: "ONEZONE_IA"
    required: true

runs:
  using: composite
  steps:
    - name: Set variable
      shell: bash
      run: |
        PREFIX=${{ github.repository }}/${{ github.ref_name }}
        KEY=${PREFIX}/${{ inputs.key }}
        echo PREFIX=${PREFIX} | tee -a $GITHUB_ENV
        echo KEY=${KEY} | tee -a $GITHUB_ENV
        
    - name: ${{ inputs.method }} cache (local)
      if: inputs.remote_path && ! startsWith(inputs.remote_path, 's3://')
      shell: bash
      run: |
        if [ "${{ inputs.method }}" = "clear" ]; then
          echo "Clearing local cache is not supported for security reason"
          exit 1
        fi

        if [ -z "${{ inputs.path }}" ]; then
          echo "Input parameter 'path' is empty"
          exit 1
        fi
        mkdir -p ${{ inputs.path }} && cd ${{ inputs.path }}
        if [ "${{ inputs.method }}" = "save" ]; then
          NUM_TARGETS=$(find . -iwholename './${{ inputs.include }}' -not -iwholename './${{ inputs.exclude }}' | wc -l)
          if [ ${NUM_TARGETS} -gt 0 ]; then
            symlinks -cr .
            mkdir -p $(dirname "${{ inputs.remote_path }}/${KEY}.cache")
            find . -iwholename './${{ inputs.include }}' -not -iwholename './${{ inputs.exclude }}' -print0 | tar -c --no-recursion --null -T - | zstd -z -${{ inputs.compress_level }} -T0 - -o ${{ inputs.remote_path }}/${KEY}.cache.new
            mv -f ${{ inputs.remote_path }}/${KEY}.cache.new ${{ inputs.remote_path }}/${KEY}.cache
            echo "${NUM_TARGETS} files/directories were saved to local ${KEY}"
            ls -l ${{ inputs.remote_path }}/${KEY}.cache
          else
            echo "No data found to save to local ${KEY}"
          fi
        elif [ "${{ inputs.method }}" = "load" ]; then
          TARGET=$(ls -l ${{ inputs.remote_path }}/${KEY}.cache 2>/dev/null || echo)
          if [ -n "${TARGET}" ]; then
            echo "Cache found"
            echo "${TARGET}"
            cat ${{ inputs.remote_path }}/${KEY}.cache | zstd -d -T0 - | tar -x .
            echo "Cache were loaded from ${KEY}"
            tree -a -I .git
          else
            echo "No local cache found to load from ${KEY}"
          fi
        else
          echo "Invalid method you have specified ${{ inputs.method }}"
          exit 1
        fi

    - name: ${{ inputs.method }} cache (S3)
      if: inputs.remote_path && startsWith(inputs.remote_path, 's3://')
      shell: bash
      run: |
        if [ "${{ inputs.method }}" = "clear" ]; then
          if [ "${{ inputs.key }}" = "all" ]; then
            aws s3 rm --recursive ${{ inputs.remote_path }}/${PREFIX}
          else
            aws s3 rm ${{ inputs.remote_path }}/${KEY}.cache
          fi
          exit 0
        fi

        if [ -z "${{ inputs.path }}" ]; then
          echo "Input parameter 'path' is empty"
          exit 1
        fi
        mkdir -p ${{ inputs.path }} && cd ${{ inputs.path }}
        if [ "${{ inputs.method }}" = "save" ]; then
          NUM_TARGETS=$(find . -iwholename './${{ inputs.include }}' -not -iwholename './${{ inputs.exclude }}' | wc -l)
          if [ ${NUM_TARGETS} -gt 0 ]; then
            symlinks -cr .
            find . -iwholename './${{ inputs.include }}' -not -iwholename './${{ inputs.exclude }}' -print0 | tar -c --no-recursion --null -T - | zstd -z -${{ inputs.compress_level }} -T0 - | aws s3 cp --storage-class ${{ inputs.storage_class }} - ${{ inputs.remote_path }}/${KEY}.cache
            echo "${NUM_TARGETS} files/directories were saved to ${KEY}"
            aws s3 ls ${{ inputs.remote_path }}/${KEY}.cache
          else
            echo "No data found to save to ${KEY}"
          fi
        elif [ "${{ inputs.method }}" = "load" ]; then
          TARGET=$(aws s3 ls ${{ inputs.remote_path }}/${KEY}.cache || echo)
          if [ -n "${TARGET}" ]; then
            echo "Cache found"
            echo "${TARGET}"
            aws s3 cp ${{ inputs.remote_path }}/${KEY}.cache - | zstd -d -T0 - | tar -x .
            echo "Cache were loaded from ${KEY}"
            tree -a -I .git
          else
            echo "No cache found to load from ${KEY}"
          fi
        else
          echo "Invalid method you have specified ${{ inputs.method }}"
          exit 1
        fi
